<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials | Kenyi&#39;Log</title>
<meta name="keywords" content="">
<meta name="description" content="
    Extended Abstract


Accurate and efficient interatomic potentials are crucial for simulating materials at the atomic level, and machine learning interatomic potentials (MLIPs) have emerged as a powerful alternative to traditional methods. A central aspect of MLIP development is the representation of local atomic environments, which significantly impacts the accuracy, transferability, and computational cost of the resulting potentials. This extended abstract reviews recent advancements in representing atomic environments for MLIPs.">
<meta name="author" content="Kenyi Takagui-Perez">
<link rel="canonical" href="https://taogenna.github.io/kenyi-blog/docs/eeml_sub/eeml_sub/">
<link crossorigin="anonymous" href="/kenyi-blog/assets/css/stylesheet.97ce433988149984f534c928fc914072e36e0e399108c98380f083ba885d9de0.css" integrity="sha256-l85DOYgUmYT1NMko/JFAcuNuDjmRCMmDgPCDuohdneA=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://taogenna.github.io/kenyi-blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://taogenna.github.io/kenyi-blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://taogenna.github.io/kenyi-blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://taogenna.github.io/kenyi-blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://taogenna.github.io/kenyi-blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://taogenna.github.io/kenyi-blog/docs/eeml_sub/eeml_sub/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
    integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"
    integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY"
    crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false }
            ]
        });
    });
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-VB0FSFKM9M"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-VB0FSFKM9M');
</script><meta property="og:url" content="https://taogenna.github.io/kenyi-blog/docs/eeml_sub/eeml_sub/">
  <meta property="og:site_name" content="Kenyi&#39;Log">
  <meta property="og:title" content="Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials">
  <meta property="og:description" content=" Extended Abstract Accurate and efficient interatomic potentials are crucial for simulating materials at the atomic level, and machine learning interatomic potentials (MLIPs) have emerged as a powerful alternative to traditional methods. A central aspect of MLIP development is the representation of local atomic environments, which significantly impacts the accuracy, transferability, and computational cost of the resulting potentials. This extended abstract reviews recent advancements in representing atomic environments for MLIPs.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
    <meta property="article:published_time" content="2025-04-12T17:57:53-05:00">
    <meta property="article:modified_time" content="2025-04-12T17:57:53-05:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials">
<meta name="twitter:description" content="
    Extended Abstract


Accurate and efficient interatomic potentials are crucial for simulating materials at the atomic level, and machine learning interatomic potentials (MLIPs) have emerged as a powerful alternative to traditional methods. A central aspect of MLIP development is the representation of local atomic environments, which significantly impacts the accuracy, transferability, and computational cost of the resulting potentials. This extended abstract reviews recent advancements in representing atomic environments for MLIPs.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Docs",
      "item": "https://taogenna.github.io/kenyi-blog/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials",
      "item": "https://taogenna.github.io/kenyi-blog/docs/eeml_sub/eeml_sub/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials",
  "name": "Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials",
  "description": " Extended Abstract Accurate and efficient interatomic potentials are crucial for simulating materials at the atomic level, and machine learning interatomic potentials (MLIPs) have emerged as a powerful alternative to traditional methods. A central aspect of MLIP development is the representation of local atomic environments, which significantly impacts the accuracy, transferability, and computational cost of the resulting potentials. This extended abstract reviews recent advancements in representing atomic environments for MLIPs.\n",
  "keywords": [
    
  ],
  "articleBody": " Extended Abstract Accurate and efficient interatomic potentials are crucial for simulating materials at the atomic level, and machine learning interatomic potentials (MLIPs) have emerged as a powerful alternative to traditional methods. A central aspect of MLIP development is the representation of local atomic environments, which significantly impacts the accuracy, transferability, and computational cost of the resulting potentials. This extended abstract reviews recent advancements in representing atomic environments for MLIPs.\nIntroduction This work surveys the development of atomic environment representations for machine learning interatomic potentials (MLIPs), crucial for accurate force fields. We trace the evolution from Behler-Parrinello’s symmetry functions through general descriptors like SOAP to the recent Cartesian Atomic Cluster Expansion (CACE). This progression highlights a shift towards systematic, symmetry-adapted representations, addressing expressiveness, efficiency, and physical fidelity by increasingly unifying completeness, invariance, and learnability. We conclude with a reflection on the current state of MLIP design.\nReviewed Papers Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces [Behler and Parinello, 2009] Behler and Parrinello (BP) proposed a neural network-based approach to approximate potential energy surfaces (PES) with near-DFT accuracy at a fraction of the computational cost, enabling simulations of large systems over small timescales.\nThe method is based on atomic energy decomposition, where the total energy $E$ of a system is expressed as a sum of atomic contributions $E=\\sum_i E_i$. Each atomic energy $E_i$ depends solely on the local chemical environment of atom $i$, in the spirit of empirical interatomic potentials.\nIn a first stage, we transform raw Cartesian coordinates corresponding to atom positions into a more suitable representation for a neural network. BP introduce a new type of symmetry function to describe the energetically relevant local environment of each atom. These symmetry functions must satisfy several crucial criteria such as uniqueness, rotational invariance, and coordination number independence. The way they are constructed is by taking positions of all neighboring atoms within a defined cutoff radius $R_c$ using a cutoff function $f_c(R_{ij})$. Finally, for each atom $i$, a vector of symmetry function values ${G^i}$ is generated, which encapsulates the essential features of its local atomic environment in a physically meaningful and invariant way.\nNow, how are these symmetry function vectors used to predict the atomic energy contributions? For each atom $i$, there is a neural network, refered to as a “subnet” $S_i$. The input to this subnet is the set of symmetry function values ${G^i}$ calculated for that atom. A crucial aspect is that all these subnets $S_i$ have the same neural network architecture (i.e., the same number of hidden layers and nodes in each layer). More importantly, all the subnets share the same set of weight parameters after the training process. Then, the neural net outputs a single value, which represents the energy contribution $E_i$ of atom $i$ to the total energy.\nOn Representing Chemical Environments [Bartok et al., 2013] While Behler and Parinello modeled the local chemical environment of an atom using symmetry functions, Bartók et al. step back and ask: what are the general requirements for a good representation of these local atomic environments? According to them, a suitable representation or descriptor must be differentiable with respect to the movement of atoms, which is essential for calculating forces needed in molecular dynamics simulations; invariant to symmetries—specifically, rotation, reflection, translation of the entire system, and permutation (swapping) of atoms of the same element—to ensure that the energy prediction doesn’t change simply because we’ve rotated our system in space or reordered identical atoms in our description; and faithful (ideally complete), meaning the descriptor should uniquely determine the atomic environment up to these symmetries.\nBart'{o}k et al. examined several families of descriptors commonly used to represent atomic environments, going beyond the specific symmetry functions introduced by BP. These families included bond-order parameters, which were shown to be related to the SO(3) power spectrum and a subset of the more general SO(3) bispectrum. The paper also explored the SO(4) power spectrum and bispectrum as a means to inherently incorporate radial information. A key methodology employed to assess these descriptors was numerical reconstruction experiments, where the ability to recover a known atomic environment from its descriptor, after a perturbation and subsequent optimization, served as a measure of the descriptor’s faithfulness. A significant finding across these families was a tendency for their faithfulness to diminish as the number of neighboring atoms increased for a descriptor of a fixed size (number of components).\nIn contrast to the explicit construction of descriptor vectors, Bartók et al. introduced the Smooth Overlap of Atomic Positions (SOAP) as an alternative paradigm that directly defines a similarity measure (a kernel) between two atomic environments. SOAP achieves this by calculating the overlap of atomic neighbor density functions, typically modeled as sums of Gaussians centered on each neighboring atom.\nCartesian Atomic CLuster Expansion (CACE) for Efficient MLIPs [Bingquing Cheng, 2024] Cheng introduces the Cartesian Atomic Cluster Expansion (CACE), a framework that reformulates the widely-used Atomic Cluster Expansion (ACE) methodology entirely in Cartesian coordinates. Traditional MLIP frameworks—such as ACE and those employing equivariant message-passing neural networks—typically express angular dependencies using spherical harmonics and impose rotational symmetry via Clebsch-Gordan coupling. In contrast, CACE constructs rotationally invariant features directly through symmetrized polynomial functions of Cartesian vectors, eliminating the need for spherical harmonics and Clebsch-Gordan coefficients while retaining mathematical equivalence.\nACE provides a systematic and complete basis for representing the potential energy of atomic systems, decomposing the local energy of an atom into contributions from its chemical environment through a body-ordered expansion:\n$$ E_i = V^{(1)}(\\mathbf{r}_i) + \\frac{1}{2} \\sum_{j} V^{(2)}(\\mathbf{r}_i, \\mathbf{r}_j) + \\frac{1}{6} \\sum_{j,k} V^{(3)}(\\mathbf{r}_i, \\mathbf{r}_j, \\mathbf{r}_k) + \\frac{1}{24} \\sum_{j,k,l} V^{(4)}(\\mathbf{r}_i, \\mathbf{r}_j, \\mathbf{r}_k, \\mathbf{r}_l) + \\cdots $$ CACE preserves this hierarchy but constructs the basis using a direct polynomial expansion in Cartesian components, followed by a rigorous symmetrization procedure to ensure rotational invariance. This yields a complete and minimal set of invariant features that are polynomially independent, in contrast to traditional ACE implementations, which may include redundant terms due to overcomplete bases.\nBeyond its novel basis construction, CACE integrates several modern ML innovations, including learnable element embeddings, flexible radial channel parametrizations, and an optional message-passing mechanism. These design choices enable CACE to achieve high accuracy, robustness, and transferability across a range of material systems, including bulk water, small organic molecules, and high-entropy alloys.\nAdditional Interpretations and Insights While symmetry functions and atomic cluster expansions provide explicit routes to invariant representations, a deeper insight lies in recognizing that these methods implicitly construct a basis in a space of geometric invariants. Behler-Parrinello’s symmetry functions, by encoding local atomic environments through radial and angular terms with specific functional forms, effectively define a non-orthogonal basis in this invariant space. ACE and CACE, with their systematic body-order expansion, aim for a more complete and polynomially independent basis. The crucial non-triviality is that the choice of this implicit geometric algebra—whether through predefined functions or a more systematic polynomial basis—strongly influences the expressiveness and the inductive bias of the resulting potential. Modern approaches, especially those incorporating message passing, can be viewed as learning to navigate and utilize this high-dimensional invariant space more effectively, adapting the effective basis functions through learnable parameters rather than relying solely on pre-engineered ones.\nConclusions The development of effective representations for atomic environments is central to advancing machine learning interatomic potentials (MLIPs). This extended abstract outlines the evolution of the field, tracing a trajectory from early empirical descriptors such as the Behler-Parrinello symmetry functions to more theoretically grounded and systematically constructed representations like SOAP and CACE. We have also discussed the limitations of each approach and how subsequent work has addressed these shortcomings. Each successive development has contributed to improving the physical accuracy, completeness, and computational efficiency of MLIPs.\nReferences [1] B. Cheng, “Cartesian atomic cluster expansion for machine learning interatomic potentials,” npj Computational Materials, vol. 10, no. 1, p. 157, 2024. DOI: 10.1038/s41524-024-01332-4.\n[2] J. Behler and M. Parrinello, “Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces,” Phys. Rev. Lett., vol. 98, no. 14, p. 146401, Apr. 2007. DOI: 10.1103/PhysRevLett.98.146401.\n[3] A.P. Bartók, R. Kondor, and G. Csányi, “On representing chemical environments,” Phys. Rev. B, vol. 87, no. 18, p. 184115, May 2013. DOI: 10.1103/PhysRevB.87.184115.\nCitation Cited as:\nTakagui-Perez, R. Kenyi. Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials, Kenyi’Log.\nhttps://taogenna.github.io/kenyi-blog/docs/EEML_sub/EEML_sub/\nOr\n@article{something, title = \"Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials\", author = \"Takagui-Perez, R. Kenyi\", journal = \"https://taogenna.github.io/kenyi-blog/\", year = \"2025\", month = \"Apr\", url = \"https://taogenna.github.io/kenyi-blog/docs/EEML_sub/EEML_sub/\" } ",
  "wordCount" : "1394",
  "inLanguage": "en",
  "datePublished": "2025-04-12T17:57:53-05:00",
  "dateModified": "2025-04-12T17:57:53-05:00",
  "author":{
    "@type": "Person",
    "name": "Kenyi Takagui-Perez"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://taogenna.github.io/kenyi-blog/docs/eeml_sub/eeml_sub/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kenyi'Log",
    "logo": {
      "@type": "ImageObject",
      "url": "https://taogenna.github.io/kenyi-blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://taogenna.github.io/kenyi-blog/" accesskey="h" title="Kenyi&#39;Log (Alt + H)">Kenyi&#39;Log</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://taogenna.github.io/kenyi-blog/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://taogenna.github.io/kenyi-blog/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://taogenna.github.io/kenyi-blog/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://taogenna.github.io/kenyi-blog/bookshelf/" title="Bookshelf">
                    <span>Bookshelf</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials
    </h1>
    <div class="post-meta"><span title='2025-04-12 17:57:53 -0500 -0500'>April 12, 2025</span>&nbsp;·&nbsp;Kenyi Takagui-Perez

</div>
  </header> 
  <div class="post-content"><div style="text-align: center;">
    Extended Abstract
</div>
<blockquote>
<p>Accurate and efficient interatomic potentials are crucial for simulating materials at the atomic level, and machine learning interatomic potentials (MLIPs) have emerged as a powerful alternative to traditional methods. A central aspect of MLIP development is the representation of local atomic environments, which significantly impacts the accuracy, transferability, and computational cost of the resulting potentials. This extended abstract reviews recent advancements in representing atomic environments for MLIPs.</p></blockquote>
<h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>This work surveys the development of atomic environment representations for machine learning interatomic potentials (MLIPs), crucial for accurate force fields. We trace the evolution from Behler-Parrinello&rsquo;s symmetry functions through general descriptors like SOAP to the recent Cartesian Atomic Cluster Expansion (CACE). This progression highlights a shift towards systematic, symmetry-adapted representations, addressing expressiveness, efficiency, and physical fidelity by increasingly unifying completeness, invariance, and learnability. We conclude with a reflection on the current state of MLIP design.</p>
<h1 id="reviewed-papers">Reviewed Papers<a hidden class="anchor" aria-hidden="true" href="#reviewed-papers">#</a></h1>
<h2 id="generalized-neural-network-representation-of-high-dimensional-potential-energy-surfaces-behler-and-parinello-2009">Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces [Behler and Parinello, 2009]<a hidden class="anchor" aria-hidden="true" href="#generalized-neural-network-representation-of-high-dimensional-potential-energy-surfaces-behler-and-parinello-2009">#</a></h2>
<p>Behler and Parrinello (BP) proposed a neural network-based approach to approximate potential energy surfaces (PES) with near-DFT accuracy at a fraction of the computational cost, enabling simulations of large systems over small timescales.</p>
<p>The method is based on atomic energy decomposition, where the total energy $E$ of a system is expressed as a sum of atomic contributions $E=\sum_i E_i$. Each atomic energy $E_i$ depends solely on the local chemical environment of atom $i$, in the spirit of empirical interatomic potentials.</p>
<p>In a first stage, we transform raw Cartesian coordinates corresponding to atom positions into a more suitable representation for a neural network. BP introduce a new type of symmetry function to describe the energetically relevant local environment of each atom. These symmetry functions must satisfy several crucial criteria such as uniqueness, rotational invariance, and coordination number independence. The way they are constructed is by taking positions of all neighboring atoms within a defined cutoff radius $R_c$ using a cutoff function $f_c(R_{ij})$. Finally, for each atom $i$, a vector of symmetry function values ${G^i}$ is generated, which encapsulates the essential features of its local atomic environment in a physically meaningful and invariant way.</p>
<p>Now, how are these symmetry function vectors used to predict the atomic energy contributions? For each atom $i$, there is a neural network, refered to as a &ldquo;subnet&rdquo; $S_i$. The input to this subnet is the set of symmetry function values ${G^i}$ calculated for that atom. A crucial aspect is that all these subnets $S_i$ have the same neural network architecture (i.e., the same number of hidden layers and nodes in each layer). More importantly, all the subnets share the same set of weight parameters after the training process. Then, the neural net outputs a single value, which represents the energy contribution $E_i$ of atom $i$ to the total energy.</p>
<h2 id="on-representing-chemical-environments-bartok-et-al-2013">On Representing Chemical Environments [Bartok et al., 2013]<a hidden class="anchor" aria-hidden="true" href="#on-representing-chemical-environments-bartok-et-al-2013">#</a></h2>
<p>While Behler and Parinello modeled the local chemical environment of an atom using symmetry functions, Bartók et al. step back and ask: what are the general requirements for a good representation of these local atomic environments? According to them, a suitable representation or descriptor must be differentiable with respect to the movement of atoms, which is essential for calculating forces needed in molecular dynamics simulations; invariant to symmetries—specifically, rotation, reflection, translation of the entire system, and permutation (swapping) of atoms of the same element—to ensure that the energy prediction doesn&rsquo;t change simply because we&rsquo;ve rotated our system in space or reordered identical atoms in our description; and faithful (ideally complete), meaning the descriptor should uniquely determine the atomic environment up to these symmetries.</p>
<p>Bart'{o}k et al. examined several families of descriptors commonly used to represent atomic environments, going beyond the specific symmetry functions introduced by BP. These families included bond-order parameters, which were shown to be related to the SO(3) power spectrum and a subset of the more general SO(3) bispectrum. The paper also explored the SO(4) power spectrum and bispectrum as a means to inherently incorporate radial information. A key methodology employed to assess these descriptors was numerical reconstruction experiments, where the ability to recover a known atomic environment from its descriptor, after a perturbation and subsequent optimization, served as a measure of the descriptor&rsquo;s faithfulness. A significant finding across these families was a tendency for their faithfulness to diminish as the number of neighboring atoms increased for a descriptor of a fixed size (number of components).</p>
<p>In contrast to the explicit construction of descriptor vectors, Bartók et al. introduced the Smooth Overlap of Atomic Positions (SOAP) as an alternative paradigm that directly defines a similarity measure (a kernel) between two atomic environments. SOAP achieves this by calculating the overlap of atomic neighbor density functions, typically modeled as sums of Gaussians centered on each neighboring atom.</p>
<h2 id="cartesian-atomic-cluster-expansion-cace-for-efficient-mlips-bingquing-cheng-2024">Cartesian Atomic CLuster Expansion (CACE) for Efficient MLIPs [Bingquing Cheng, 2024]<a hidden class="anchor" aria-hidden="true" href="#cartesian-atomic-cluster-expansion-cace-for-efficient-mlips-bingquing-cheng-2024">#</a></h2>
<p>Cheng introduces the Cartesian Atomic Cluster Expansion (CACE), a framework that reformulates the widely-used Atomic Cluster Expansion (ACE) methodology entirely in Cartesian coordinates. Traditional MLIP frameworks—such as ACE and those employing equivariant message-passing neural networks—typically express angular dependencies using spherical harmonics and impose rotational symmetry via Clebsch-Gordan coupling. In contrast, CACE constructs rotationally invariant features directly through symmetrized polynomial functions of Cartesian vectors, eliminating the need for spherical harmonics and Clebsch-Gordan coefficients while retaining mathematical equivalence.</p>
<p>ACE provides a systematic and complete basis for representing the potential energy of atomic systems, decomposing the local energy of an atom into contributions from its chemical environment through a body-ordered expansion:</p>

$$

E_i = V^{(1)}(\mathbf{r}_i) + \frac{1}{2} \sum_{j} V^{(2)}(\mathbf{r}_i, \mathbf{r}_j) + \frac{1}{6} \sum_{j,k} V^{(3)}(\mathbf{r}_i, \mathbf{r}_j, \mathbf{r}_k) + \frac{1}{24} \sum_{j,k,l} V^{(4)}(\mathbf{r}_i, \mathbf{r}_j, \mathbf{r}_k, \mathbf{r}_l) + \cdots
$$ 

<p>CACE preserves this hierarchy but constructs the basis using a direct polynomial expansion in Cartesian components, followed by a rigorous symmetrization procedure to ensure rotational invariance. This yields a complete and minimal set of invariant features that are polynomially independent, in contrast to traditional ACE implementations, which may include redundant terms due to overcomplete bases.</p>
<p>Beyond its novel basis construction, CACE integrates several modern ML innovations, including learnable element embeddings, flexible radial channel parametrizations, and an optional message-passing mechanism. These design choices enable CACE to achieve high accuracy, robustness, and transferability across a range of material systems, including bulk water, small organic molecules, and high-entropy alloys.</p>
<h2 id="additional-interpretations-and-insights">Additional Interpretations and Insights<a hidden class="anchor" aria-hidden="true" href="#additional-interpretations-and-insights">#</a></h2>
<p>While symmetry functions and atomic cluster expansions provide explicit routes to invariant representations, a deeper insight lies in recognizing that these methods implicitly construct a basis in a space of geometric invariants. Behler-Parrinello&rsquo;s symmetry functions, by encoding local atomic environments through radial and angular terms with specific functional forms, effectively define a non-orthogonal basis in this invariant space. ACE and CACE, with their systematic body-order expansion, aim for a more complete and polynomially independent basis. The crucial non-triviality is that the choice of this implicit geometric algebra—whether through predefined functions or a more systematic polynomial basis—strongly influences the expressiveness and the inductive bias of the resulting potential. Modern approaches, especially those incorporating message passing, can be viewed as learning to navigate and utilize this high-dimensional invariant space more effectively, adapting the effective basis functions through learnable parameters rather than relying solely on pre-engineered ones.</p>
<h2 id="conclusions">Conclusions<a hidden class="anchor" aria-hidden="true" href="#conclusions">#</a></h2>
<p>The development of effective representations for atomic environments is central to advancing machine learning interatomic potentials (MLIPs). This extended abstract outlines the evolution of the field, tracing a trajectory from early empirical descriptors such as the Behler-Parrinello symmetry functions to more theoretically grounded and systematically constructed representations like SOAP and CACE. We have also discussed the limitations of each approach and how subsequent work has addressed these shortcomings. Each successive development has contributed to improving the physical accuracy, completeness, and computational efficiency of MLIPs.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] B. Cheng, &ldquo;Cartesian atomic cluster expansion for machine learning interatomic potentials,&rdquo; <em>npj Computational Materials</em>, vol. 10, no. 1, p. 157, 2024. DOI: <a href="https://doi.org/10.1038/s41524-024-01332-4">10.1038/s41524-024-01332-4</a>.</p>
<p>[2] J. Behler and M. Parrinello, &ldquo;Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces,&rdquo; <em>Phys. Rev. Lett.</em>, vol. 98, no. 14, p. 146401, Apr. 2007. DOI: <a href="https://link.aps.org/doi/10.1103/PhysRevLett.98.146401">10.1103/PhysRevLett.98.146401</a>.</p>
<p>[3] A.P. Bartók, R. Kondor, and G. Csányi, &ldquo;On representing chemical environments,&rdquo; <em>Phys. Rev. B</em>, vol. 87, no. 18, p. 184115, May 2013. DOI: <a href="https://link.aps.org/doi/10.1103/PhysRevB.87.184115">10.1103/PhysRevB.87.184115</a>.</p>
<h1 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h1>
<p>Cited as:</p>
<blockquote>
<p>Takagui-Perez, R. Kenyi. Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials, Kenyi&rsquo;Log.<br>
<a href="https://taogenna.github.io/kenyi-blog/docs/EEML_sub/EEML_sub/">https://taogenna.github.io/kenyi-blog/docs/EEML_sub/EEML_sub/</a></p></blockquote>
<p>Or</p>
<pre tabindex="0"><code>@article{something,
  title   = &#34;Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials&#34;,
  author  = &#34;Takagui-Perez, R. Kenyi&#34;,
  journal = &#34;https://taogenna.github.io/kenyi-blog/&#34;,
  year    = &#34;2025&#34;,
  month   = &#34;Apr&#34;,
  url     = &#34;https://taogenna.github.io/kenyi-blog/docs/EEML_sub/EEML_sub/&#34;
}
</code></pre>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on x"
            href="https://x.com/intent/tweet/?text=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials&amp;url=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f&amp;title=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials&amp;summary=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials&amp;source=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f&title=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on whatsapp"
            href="https://api.whatsapp.com/send?text=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials%20-%20https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on telegram"
            href="https://telegram.me/share/url?text=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials&amp;url=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advancements in Representing Atomic Environments for Machine Learning Interatomic Potentials on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Advancements%20in%20Representing%20Atomic%20Environments%20for%20Machine%20Learning%20Interatomic%20Potentials&u=https%3a%2f%2ftaogenna.github.io%2fkenyi-blog%2fdocs%2feeml_sub%2feeml_sub%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://taogenna.github.io/kenyi-blog/">Kenyi&#39;Log</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
